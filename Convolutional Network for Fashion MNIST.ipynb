{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Convolutional Neural Network for Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal will be to train a convolutional neural network on the Fashion MNIST dataset. The Fashion MNIST dataset was\n",
    "created out of an effort to replace MNIST as a go-to benchmarking dataset for CV algos, so I, lacking in experience with convolutional neural networks, decided to tackle implementing and training a model against it. This is just a documentation of the process of doing so for fun. Perhaps it will be useful to someone else. (I have ignored some of the deprecation warnings from tensorflow since this is just a personal program, and not intended for professional use.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Luckily, Keras already has the dataset ready to download and use easily. No data manipulation of our own is needed :). We start off by importing some needed things. We also normalize our images to have values in the range of [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\alex\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import conv2d\n",
    "from tensorflow.contrib.layers import flatten\n",
    "from tensorflow.contrib.layers import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test_scalar_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "num_classes = 10\n",
    "\n",
    "# normalize the images\n",
    "x_train = (1/255)*x_train\n",
    "x_test = (1/255)*x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also prepare our labels as one-hot vectors instead of scalars as they were originally represented. Simply picking the label'th row from an identity matrix with num_classes rows makes this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([np.identity(num_classes)[label] for label in y_train])\n",
    "y_test = np.array([np.identity(num_classes)[label] for label in y_test_scalar_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the images from the dataset can be seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some placeholders must be created next! We keep a vector of scalar label values so we can use them to easily compute accuracy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 10))\n",
    "y_scalars = tf.placeholder(dtype=tf.float32, shape=(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolutional Layer\n",
    "\n",
    "Next, we define elements for our one and only convolutional layer in the network. We will have 20 filters, each of size 7x7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_filter_count = 20\n",
    "conv1_filter_size = 7\n",
    "conv1_layer = conv2d(inputs=tf.expand_dims(x, 3), num_outputs=conv1_filter_count,\n",
    "                    kernel_size=[conv1_filter_size, conv1_filter_size], padding='SAME',\n",
    "                    stride=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this convolutional layer will be a rectangular tensor. We will flatten it so we can feed it to the fully connected layer on the end of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = flatten(conv1_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fully Connected Layer\n",
    "\n",
    "We must then initialize our weight matrix. We will use Xavier initialization, an advanced and optimal form of weight initialization. The definition of the matrix multiplication that transforms the filters into our prediction vectors follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weights = tf.get_variable(name='fc1_weights', shape=[flattened.shape[1], num_classes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "fc1_layer = tf.matmul(flattened, fc1_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimization\n",
    "\n",
    "In order to train our model, we must apply an optimizer to a differentiable error function. We will compute the cross entropy losses, sum them up, and square them. We will use batch gradient descent with some momentum for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=fc1_layer))\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=0.2, momentum=0.9).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will compute the number of correct predictions that we can use later to get an accuracy percentage, which is alot nicer to interpret than our loss function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_sum(tf.cast(tf.equal(tf.argmax(fc1_layer, axis=1), tf.cast(y_scalars, tf.int64)), tf.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the model loose on the training data\n",
    "\n",
    "Now we can train for a while and see how well the model does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 accuracy: 21.84%\n",
      "epoch 1 accuracy: 31.18%\n",
      "epoch 2 accuracy: 55.91%\n",
      "epoch 3 accuracy: 30.13%\n",
      "epoch 4 accuracy: 47.36%\n",
      "epoch 5 accuracy: 35.62%\n",
      "epoch 6 accuracy: 33.67%\n",
      "epoch 7 accuracy: 37.79%\n",
      "epoch 8 accuracy: 48.47%\n",
      "epoch 9 accuracy: 60.49%\n",
      "epoch 10 accuracy: 55.92%\n",
      "epoch 11 accuracy: 64.87%\n",
      "epoch 12 accuracy: 65.84%\n",
      "epoch 13 accuracy: 68.85%\n",
      "epoch 14 accuracy: 68.29%\n",
      "epoch 15 accuracy: 70.54%\n",
      "epoch 16 accuracy: 69.37%\n",
      "epoch 17 accuracy: 71.48%\n",
      "epoch 18 accuracy: 73.23%\n",
      "epoch 19 accuracy: 72.59%\n",
      "epoch 20 accuracy: 74.99%\n",
      "epoch 21 accuracy: 75.01%\n",
      "epoch 22 accuracy: 75.62%\n",
      "epoch 23 accuracy: 77.46%\n",
      "epoch 24 accuracy: 77.3%\n",
      "epoch 25 accuracy: 78.0%\n",
      "epoch 26 accuracy: 78.61%\n",
      "epoch 27 accuracy: 79.08%\n",
      "epoch 28 accuracy: 79.54%\n",
      "epoch 29 accuracy: 79.83%\n",
      "epoch 30 accuracy: 79.68%\n",
      "epoch 31 accuracy: 80.78%\n",
      "epoch 32 accuracy: 80.58%\n",
      "epoch 33 accuracy: 80.93%\n",
      "epoch 34 accuracy: 81.38%\n",
      "epoch 35 accuracy: 81.68%\n",
      "epoch 36 accuracy: 81.98%\n",
      "epoch 37 accuracy: 82.26%\n",
      "epoch 38 accuracy: 82.1%\n",
      "epoch 39 accuracy: 82.61%\n",
      "epoch 40 accuracy: 82.46%\n",
      "epoch 41 accuracy: 82.77%\n",
      "epoch 42 accuracy: 82.77%\n",
      "epoch 43 accuracy: 83.18%\n",
      "epoch 44 accuracy: 83.35%\n",
      "epoch 45 accuracy: 83.06%\n",
      "epoch 46 accuracy: 83.24%\n",
      "epoch 47 accuracy: 83.34%\n",
      "epoch 48 accuracy: 83.58%\n",
      "epoch 49 accuracy: 83.54%\n",
      "epoch 50 accuracy: 83.84%\n",
      "epoch 51 accuracy: 83.91%\n",
      "epoch 52 accuracy: 83.89%\n",
      "epoch 53 accuracy: 84.02%\n",
      "epoch 54 accuracy: 84.16%\n",
      "epoch 55 accuracy: 84.36%\n",
      "epoch 56 accuracy: 84.28%\n",
      "epoch 57 accuracy: 84.58%\n",
      "epoch 58 accuracy: 84.55%\n",
      "epoch 59 accuracy: 84.5%\n",
      "epoch 60 accuracy: 84.59%\n",
      "epoch 61 accuracy: 84.66%\n",
      "epoch 62 accuracy: 84.72%\n",
      "epoch 63 accuracy: 84.78%\n",
      "epoch 64 accuracy: 84.87%\n",
      "epoch 65 accuracy: 84.92%\n",
      "epoch 66 accuracy: 84.95%\n",
      "epoch 67 accuracy: 84.95%\n",
      "epoch 68 accuracy: 85.0%\n",
      "epoch 69 accuracy: 85.14%\n",
      "epoch 70 accuracy: 85.06%\n",
      "epoch 71 accuracy: 85.14%\n",
      "epoch 72 accuracy: 85.23%\n",
      "epoch 73 accuracy: 85.3%\n",
      "epoch 74 accuracy: 85.35%\n",
      "epoch 75 accuracy: 85.41%\n",
      "epoch 76 accuracy: 85.45%\n",
      "epoch 77 accuracy: 85.44%\n",
      "epoch 78 accuracy: 85.58%\n",
      "epoch 79 accuracy: 85.55%\n",
      "epoch 80 accuracy: 85.58%\n",
      "epoch 81 accuracy: 85.63%\n",
      "epoch 82 accuracy: 85.71%\n",
      "epoch 83 accuracy: 85.84%\n",
      "epoch 84 accuracy: 85.8%\n",
      "epoch 85 accuracy: 85.88%\n",
      "epoch 86 accuracy: 85.91%\n",
      "epoch 87 accuracy: 86.06%\n",
      "epoch 88 accuracy: 86.13%\n",
      "epoch 89 accuracy: 86.11%\n",
      "epoch 90 accuracy: 86.19%\n",
      "epoch 91 accuracy: 86.21%\n",
      "epoch 92 accuracy: 86.3%\n",
      "epoch 93 accuracy: 86.31%\n",
      "epoch 94 accuracy: 86.35%\n",
      "epoch 95 accuracy: 86.4%\n",
      "epoch 96 accuracy: 86.39%\n",
      "epoch 97 accuracy: 86.41%\n",
      "epoch 98 accuracy: 86.42%\n",
      "epoch 99 accuracy: 86.48%\n",
      "epoch 100 accuracy: 86.45%\n",
      "epoch 101 accuracy: 86.45%\n",
      "epoch 102 accuracy: 86.44%\n",
      "epoch 103 accuracy: 86.43%\n",
      "epoch 104 accuracy: 86.5%\n",
      "epoch 105 accuracy: 86.55%\n",
      "epoch 106 accuracy: 86.59%\n",
      "epoch 107 accuracy: 86.55%\n",
      "epoch 108 accuracy: 86.58%\n",
      "epoch 109 accuracy: 86.55%\n",
      "epoch 110 accuracy: 86.55%\n",
      "epoch 111 accuracy: 86.61%\n",
      "epoch 112 accuracy: 86.59%\n",
      "epoch 113 accuracy: 86.58%\n",
      "epoch 114 accuracy: 86.6%\n",
      "epoch 115 accuracy: 86.64%\n",
      "epoch 116 accuracy: 86.69%\n",
      "epoch 117 accuracy: 86.67%\n",
      "epoch 118 accuracy: 86.71%\n",
      "epoch 119 accuracy: 86.72%\n",
      "epoch 120 accuracy: 86.75%\n",
      "epoch 121 accuracy: 86.74%\n",
      "epoch 122 accuracy: 86.74%\n",
      "epoch 123 accuracy: 86.75%\n",
      "epoch 124 accuracy: 86.75%\n",
      "epoch 125 accuracy: 86.78%\n",
      "epoch 126 accuracy: 86.78%\n",
      "epoch 127 accuracy: 86.74%\n",
      "epoch 128 accuracy: 86.77%\n",
      "epoch 129 accuracy: 86.74%\n",
      "epoch 130 accuracy: 86.77%\n",
      "epoch 131 accuracy: 86.76%\n",
      "epoch 132 accuracy: 86.78%\n",
      "epoch 133 accuracy: 86.81%\n",
      "epoch 134 accuracy: 86.84%\n",
      "epoch 135 accuracy: 86.84%\n",
      "epoch 136 accuracy: 86.8%\n",
      "epoch 137 accuracy: 86.82%\n",
      "epoch 138 accuracy: 86.81%\n",
      "epoch 139 accuracy: 86.84%\n",
      "epoch 140 accuracy: 86.84%\n",
      "epoch 141 accuracy: 86.84%\n",
      "epoch 142 accuracy: 86.87%\n",
      "epoch 143 accuracy: 86.89%\n",
      "epoch 144 accuracy: 86.85%\n",
      "epoch 145 accuracy: 86.86%\n",
      "epoch 146 accuracy: 86.87%\n",
      "epoch 147 accuracy: 86.9%\n",
      "epoch 148 accuracy: 86.9%\n",
      "epoch 149 accuracy: 86.9%\n",
      "epoch 150 accuracy: 86.9%\n",
      "epoch 151 accuracy: 86.93%\n",
      "epoch 152 accuracy: 86.96%\n",
      "epoch 153 accuracy: 86.97%\n",
      "epoch 154 accuracy: 86.99%\n",
      "epoch 155 accuracy: 86.96%\n",
      "epoch 156 accuracy: 86.98%\n",
      "epoch 157 accuracy: 86.97%\n",
      "epoch 158 accuracy: 86.98%\n",
      "epoch 159 accuracy: 86.99%\n",
      "epoch 160 accuracy: 87.0%\n",
      "epoch 161 accuracy: 87.04%\n",
      "epoch 162 accuracy: 86.97%\n",
      "epoch 163 accuracy: 87.05%\n",
      "epoch 164 accuracy: 87.0%\n",
      "epoch 165 accuracy: 87.11%\n",
      "epoch 166 accuracy: 87.02%\n",
      "epoch 167 accuracy: 87.27%\n",
      "epoch 168 accuracy: 87.1%\n",
      "epoch 169 accuracy: 87.4%\n",
      "epoch 170 accuracy: 86.99%\n",
      "epoch 171 accuracy: 87.21%\n",
      "epoch 172 accuracy: 86.57%\n",
      "epoch 173 accuracy: 86.52%\n",
      "epoch 174 accuracy: 85.36%\n",
      "epoch 175 accuracy: 85.74%\n",
      "epoch 176 accuracy: 85.72%\n",
      "epoch 177 accuracy: 87.25%\n",
      "epoch 178 accuracy: 87.12%\n",
      "epoch 179 accuracy: 86.37%\n",
      "epoch 180 accuracy: 87.07%\n",
      "epoch 181 accuracy: 87.35%\n",
      "epoch 182 accuracy: 86.92%\n",
      "epoch 183 accuracy: 86.84%\n",
      "epoch 184 accuracy: 87.05%\n",
      "epoch 185 accuracy: 87.53%\n",
      "epoch 186 accuracy: 87.27%\n",
      "epoch 187 accuracy: 86.88%\n",
      "epoch 188 accuracy: 87.32%\n",
      "epoch 189 accuracy: 87.35%\n",
      "epoch 190 accuracy: 87.27%\n",
      "epoch 191 accuracy: 87.26%\n",
      "epoch 192 accuracy: 87.34%\n",
      "epoch 193 accuracy: 87.38%\n",
      "epoch 194 accuracy: 87.43%\n",
      "epoch 195 accuracy: 87.42%\n",
      "epoch 196 accuracy: 87.54%\n",
      "epoch 197 accuracy: 87.44%\n",
      "epoch 198 accuracy: 87.49%\n",
      "epoch 199 accuracy: 87.58%\n",
      "epoch 200 accuracy: 87.53%\n",
      "epoch 201 accuracy: 87.55%\n",
      "epoch 202 accuracy: 87.5%\n",
      "epoch 203 accuracy: 87.52%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(204):\n",
    "      sess.run(optimizer, feed_dict={x:x_train, y:y_train, y_scalars:[]})\n",
    "      print(\"epoch \" + str(i) + \" accuracy: \" + str(100*sess.run(accuracy, feed_dict={x:x_test, y:y_test, y_scalars:y_test_scalar_labels}) / len(y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a total of 204 epochs, we obtain an accuracy of ~88%. Not bad, but perhaps we can get it up in the 90's by adding some other elements to the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
